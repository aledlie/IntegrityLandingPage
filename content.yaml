# =============================================================================
# INTEGRITY STUDIO CONTENT CONFIGURATION
# =============================================================================
# All marketing copy, UI text, and content in one place.
# Edit this file to update content across the entire application.
# =============================================================================

# =============================================================================
# COMPANY INFORMATION
# =============================================================================
_meta:
  last_reviewed: "2026-01-30"
  review_owner: "marketing"

company:
  name: "Integrity Studio"
  tagline: "AI Observability That Proves Compliance"
  copyright: "Â© 2026 Integrity Studio. All rights reserved."
  founded_year: "2025"
  location:
    city: "Austin"
    region: "Texas"
  contact:
    email: "hello@integritystudio.ai"
    phone: "(512) 829-1644"

# =============================================================================
# EXTERNAL URLS
# =============================================================================
urls:
  external:
    calendly_demo: "https://calendly.com/alyshialedlie/30min"
    status_page: "https://integritystudio.ai/status"
    linkedin: "https://linkedin.com/company/integrity-studio-ai"
    twitter: "https://twitter.com/integritystudio"
    github: "https://github.com/aledlie"
    founder_linkedin: "https://linkedin.com/in/aledlie"
    founder_twitter: "https://twitter.com/alyshialedlie"

  internal:
    home: "/"
    blog: "/blog"
    docs: "/docs"
    pricing: "/pricing"
    about: "/about"
    contact: "/contact"
    signup: "/signup"
    features: "#features"
    pricing_section: "#pricing"
    services: "#services"
    demo: "#demo"
    docs_quickstart: "/docs/quickstart"
    docs_api: "/docs/api"
    docs_compliance: "/docs/compliance"
    docs_integrations: "/docs/integrations"
    docs_tracing: "/docs/tracing"
    docs_agents: "/docs/agents"
    docs_alerts: "/docs/alerts"
    eu_ai_act: "/eu-ai-act"
    support: "/support"
    api: "/api"
    careers: "/careers"
    privacy: "/privacy"
    terms: "/terms"
    cookies: "/cookies"
    accessibility: "/accessibility"
    whylabs_alternative: "/whylabs-alternative"
    arize_alternative: "/compare/arize-ai-alternative"
    sources: "/sources"

# =============================================================================
# CTA BUTTON TEXT
# =============================================================================
cta_text:
  primary:
    start_free_trial: "Start Free Trial"
    get_started: "Get Started"
    schedule_demo: "Schedule Demo"
    request_demo: "Request Demo"
    contact_sales: "Contact Sales"
    learn_more: "Learn More"
  navigation:
    back_to_home: "Back to Home"
    view_all: "View All"
    view_docs: "View Documentation"
  form:
    send_message: "Send Message"
    download_now: "Download Now"
    calculate_savings: "Calculate Savings"

# =============================================================================
# TRUST INDICATORS
# =============================================================================
trust_indicators:
  current:
    - "EU AI Act Ready"
    - "Enterprise Security"
    - "99.9% Uptime"
    - "15-min Setup"
  legacy:
    - "No credit card required"
    - "14-day free trial"
    - "Cancel anytime"

# =============================================================================
# PLATFORM METRICS
# =============================================================================
platform_metrics:
  uptime: &uptime "99.9%"
  uptime_sla: &uptime_sla "SLA Guaranteed"
  traces_processed: &traces_processed "10M+ (Jan 2026)"
  traces_processed_period: &traces_period "Daily"
  setup_time: &setup_time "15 min"
  setup_time_label: &setup_label "Average"

# =============================================================================
# PRICING CONSTANTS
# =============================================================================
pricing_constants:
  annual_discount: "Save 20%"
  monthly_label: "Monthly"
  annual_label: "Annual"
  enterprise_note: "Need custom solutions? "
  enterprise_link: "Contact our sales team"
  tiers:
    free:
      traces_limit: "50K traces/month"
      retention: "7-day retention"
    team:
      traces_limit: "500K traces/month"
      retention: "30-day retention"
    enterprise:
      traces_limit: "Unlimited traces"
      retention: "1-year retention"

# =============================================================================
# FORM MESSAGES
# =============================================================================
form_messages:
  contact:
    success: "Thank you for reaching out! We'll get back to you within one business day."
    error: "Something went wrong. Please try again or email us directly at hello@integritystudio.ai"
  subscribe:
    success: "Thanks for subscribing!"
    error: "Could not subscribe. Please try again."

# =============================================================================
# PROMO CODES
# =============================================================================
promo_codes:
  whylabs_migration:
    code: "WHYLABS2026"
    description: "Get 3 months free on Team tier when you migrate from WhyLabs. Use code WHYLABS2026 at checkout."

# =============================================================================
# COMPLIANCE DISCLAIMERS
# =============================================================================
disclaimers:
  eu_ai_act: >-
    Integrity Studio provides tools designed to support EU AI Act compliance efforts.
    Actual compliance requires independent legal review, third-party assessment, and
    organization-specific implementation. This platform does not constitute legal advice
    or guarantee regulatory compliance.
  eu_ai_act_short: "Tools to support EU AI Act compliance efforts."
  security: >-
    Security certifications in progress. Current measures include encryption at rest
    and in transit, regular penetration testing, and adherence to OWASP guidelines.
  human_oversight: >-
    Human oversight tools provide technical infrastructure for approval workflows.
    Organizations are responsible for defining oversight policies, training reviewers,
    and ensuring meaningful human review of AI decisions.
  general: >-
    This platform provides tools to support AI governance and observability.
    It does not guarantee regulatory compliance or constitute legal advice.

# =============================================================================
# CITED STATISTICS
# =============================================================================
statistics:
  _meta:
    last_reviewed: "2026-01-30"
    review_owner: "marketing"
  industry:
    market_size:
      value: "$8.1B"
      label: "market by 2034"
      source: "Market.us, LLM Observability Platform Market Report 2025"
      source_url: "https://market.us/report/llm-observability-platform-market/"
    market_growth:
      value: "44%"
      label: "YoY AI spending growth"
      source: "Gartner AI Spending Forecast, January 2026"
      source_url: "https://www.gartner.com/en/newsroom/press-releases/2026-1-15-gartner-says-worldwide-ai-spending-will-total-2-point-5-trillion-dollars-in-2026"
    enterprise_budgets:
      value: "98%"
      label: "enterprises increasing AI budgets"
      source: "Gartner CIO Survey 2024"
      source_url: "https://www.gartner.com/en/information-technology/insights/cio-agenda"
  customer_data:
    debugging_improvement:
      value: "73%"
      label: "faster debugging"
      source: "Aggregated data from all sessions, Q4 2025"
    cost_reduction:
      value: "30-50%"
      label: "LLM cost reduction"
      source: "Metrics-tracked savings, 2025"
  platform:
    traces_processed:
      value: *traces_processed
      label: "traces processed"
      source: "Platform metrics, January 2026"
    setup_time:
      value: *setup_time
      label: "setup time"
      source: "Average onboarding time, 2025"
    uptime_target:
      value: *uptime
      label: "uptime SLA"
      source: "Service Level Agreement target"
  source_disclaimer: >-
    Statistics from customer data are aggregated and anonymized.
    Industry statistics sourced from third-party research reports.
    See integritystudio.ai/sources for full methodology and citations.

# =============================================================================
# HERO SECTION
# =============================================================================
hero:
  current:
    badge: "EU AI Act Ready"
    headline: "AI Observability That\nProves Compliance"
    subheadline: >-
      Full traceability for every LLM decision.
      Automated risk documentation. Audit-ready from day one.
      Enterprise-grade monitoring with compliance built-in.
    primary_cta: "Start Free Trial"
    secondary_cta: "Request Demo"

  variants:
    agent_first:
      badge: "AI Observability Platform"
      headline: "See Every Decision\nYour AI Agents Make"
      subheadline: >-
        End-to-end visibility into your AI agent workflows.
        Track performance, debug issues, and optimize costs
        with comprehensive tracing and analytics.
      primary_cta: "Start Free Trial"
      secondary_cta: "Request Demo"

    cost_focused:
      badge: "LLM Cost Intelligence"
      headline: "Know Your AI Spend\nBefore It Surprises You"
      subheadline: >-
        Real-time cost tracking for every LLM call.
        Set budgets, get alerts, and optimize spend
        with granular token-level attribution.
      primary_cta: "Start Free Trial"
      secondary_cta: "Request Demo"

    legacy:
      badge: "AI Observability Platform"
      headline: "Understand Your\nAI in Production"
      subheadline: >-
        Enterprise-grade observability for LLM applications.
        Monitor performance, track costs, and debug issues
        with comprehensive tracing and analytics.
      primary_cta: "Start Free Trial"
      secondary_cta: "Request Demo"

# =============================================================================
# PRICING SECTION
# =============================================================================
pricing:
  _meta:
    last_reviewed: "2026-01-30"
    review_owner: "marketing"
  title: "Simple, Transparent Pricing"
  subtitle: "Start free, scale as you grow"

  tiers:
    - name: "Starter"
      monthly_price: "Free"
      annual_price: "Free"
      description: "For individual developers"
      cta_text: "Get Started"
      features:
        - "50K traces/month"
        - "7-day retention"
        - "Basic dashboards"
        - "Email support"
        - "Community access"

    - name: "Team"
      monthly_price: "$99"
      annual_price: "$79"
      period: "/month"
      description: "For growing teams"
      is_popular: true
      cta_text: "Start Free Trial"
      features:
        - "500K traces/month"
        - "30-day retention"
        - "Advanced analytics"
        - "Priority support"
        - "Team collaboration"
        - "Custom alerts"
        - "EU AI Act reports"

    - name: "Enterprise"
      monthly_price: "Custom"
      annual_price: "Custom"
      description: "For large organizations"
      cta_text: "Contact Sales"
      features:
        - "Unlimited traces"
        - "1-year retention"
        - "SSO/SAML"
        - "Dedicated support"
        - "Custom integrations"
        - "SLA guarantee"
        - "On-premise option"
        - "Compliance dashboard"

# =============================================================================
# FEATURES SECTION
# =============================================================================
features:
  title: "Platform Capabilities"
  subtitle: "Comprehensive tools for AI application observability"

  items:
    - icon: "activity"
      title: "LLM Monitoring"
      description: "Track every LLM call with detailed performance metrics and cost attribution."
      bullets:
        - "Token usage tracking"
        - "Latency monitoring"
        - "Cost attribution per request"

    - icon: "git-branch"
      title: "Distributed Tracing"
      description: "End-to-end visibility across your AI application with OpenTelemetry support."
      bullets:
        - "Request correlation"
        - "Service dependency mapping"
        - "Bottleneck identification"

    - icon: "clipboard-check"
      title: "Compliance Reporting"
      description: "Automated documentation for EU AI Act Article 12 requirements."
      bullets:
        - "Audit trail generation"
        - "Risk classification support"
        - "Decision traceability"

    - icon: "shield"
      title: "Security & Privacy"
      description: "Enterprise-grade security with PII detection and data masking."
      bullets:
        - "Automatic PII redaction"
        - "Role-based access control"
        - "GDPR compliance tools"

    - icon: "bar-chart-3"
      title: "Analytics Dashboard"
      description: "Customizable dashboards with real-time metrics and historical trends."
      bullets:
        - "Custom visualizations"
        - "Export capabilities"
        - "Team collaboration"

    - icon: "alert-triangle"
      title: "Anomaly Detection"
      description: "Automated detection of performance regressions and unusual patterns."
      bullets:
        - "Baseline comparison"
        - "Custom alert thresholds"
        - "Slack/PagerDuty integration"

# =============================================================================
# SERVICES SECTION
# =============================================================================
services:
  section_id: "services"
  title: "Platform Services"
  subtitle: "Comprehensive AI Observability for Enterprise"
  description: >-
    From real-time LLM monitoring to automated compliance reporting,
    Integrity Studio provides the complete toolkit for production AI systems.
    Built for teams who need visibility, governance, and audit-ready documentation.
  cta_text: "Start Free Trial"
  cta_url: "/signup"

  items:
    - icon: "activity"
      title: "LLM Monitoring & Tracing"
      description: >-
        Track every LLM call with sub-100ms latency. Capture prompts, completions,
        tokens, costs, and performance metrics in real-time across all your models.
      cta_text: "View Tracing Docs"
      cta_url: "/docs/tracing"
      capabilities:
        - "Full request/response capture with token attribution"
        - "Cost tracking per request, model, and team"
        - "Latency percentiles and performance baselines"
        - "Multi-provider support (OpenAI, Anthropic, Google, AWS Bedrock)"
        - "OpenTelemetry-native instrumentation"

    - icon: "bot"
      title: "Agent Observability"
      description: >-
        Monitor multi-step AI agents, tool calls, and reasoning chains.
        Debug complex autonomous workflows with full execution traces and decision visualization.
      cta_text: "Explore Agent Features"
      cta_url: "/docs/agents"
      capabilities:
        - "Multi-turn conversation tracking"
        - "Tool call monitoring with input/output capture"
        - "Reasoning chain visualization"
        - "Agent decision tree analysis"
        - "LangChain, LlamaIndex, and custom agent support"

    - icon: "shield"
      title: "Compliance & Governance"
      description: >-
        Built-in EU AI Act templates, automated audit trails, and framework mapping.
        Prepare for regulatory requirements with documentation that stands up to scrutiny.
      cta_text: "EU AI Act Guide"
      cta_url: "/eu-ai-act"
      disclaimer: "Tools to support EU AI Act compliance efforts."
      capabilities:
        - "EU AI Act Article 12 traceability requirements"
        - "Automated risk classification support"
        - "Audit trail generation with immutable logs"
        - "Human oversight tracking and approval workflows"
        - "GDPR-compliant data handling and retention"

    - icon: "bar-chart-3"
      title: "Analytics & Dashboards"
      description: >-
        Interactive dashboards for token usage, costs, latency distributions,
        and model comparison analytics. Export data for stakeholder reporting.
      cta_text: "See Dashboard Demo"
      cta_url: "#demo"
      capabilities:
        - "Customizable KPI dashboards"
        - "Historical trend analysis"
        - "Model performance benchmarking"
        - "Team and project attribution"
        - "Export to CSV, JSON, and PDF"

    - icon: "bell"
      title: "Alerting & Incident Management"
      description: >-
        Proactive alerting for anomalies, budget thresholds, and performance degradation.
        Intelligent routing to your existing incident management tools.
      cta_text: "Configure Alerts"
      cta_url: "/docs/alerts"
      capabilities:
        - "Budget alerts before cost overruns"
        - "Anomaly detection for response quality"
        - "Performance regression warnings"
        - "Slack, PagerDuty, and webhook integrations"
        - "Custom alert thresholds and schedules"

    - icon: "code"
      title: "Developer Experience"
      description: >-
        Drop-in SDKs for Python, TypeScript, and Go. OpenTelemetry-native with
        minimal instrumentation required. Get to value in under 5 minutes.
      cta_text: "Quick Start Guide"
      cta_url: "/docs/quickstart"
      capabilities:
        - "Python, TypeScript, and Go SDKs"
        - "Auto-instrumentation for popular frameworks"
        - "OpenTelemetry compatibility"
        - "Comprehensive API documentation"
        - "Self-hosted and cloud deployment options"

# =============================================================================
# CTA SECTION
# =============================================================================
cta:
  headline: "Ready to Gain Visibility Into Your AI?"
  subheadline: "Join teams who trust Integrity Studio for AI observability with compliance built-in."
  primary_cta: "Start Free Trial"
  secondary_cta: "Schedule Demo"

# =============================================================================
# SOCIAL PROOF SECTION
# =============================================================================
social_proof:
  _meta:
    last_reviewed: "2026-01-30"
    review_owner: "marketing"
  title: "Trusted by AI Teams"
  stats_headline: "Enterprise-Grade Performance"

  stats:
    traces_processed: *traces_processed
    uptime: *uptime
    setup_time: *setup_time

  # Placeholder logos (to be replaced with real customers)
  # TODO: Uncomment when customer logos are approved for use
  # logos:
  #   - name: "Granica.ai"
  #     industry: "Cutting Edge Data Services"
  #   - name: "DotFun"
  #     industry: "SaaS"
  #   - name: "Leora Home Health Care"
  #     industry: "Healthcare"
  #   - name: "Hines Financial Group"
  #     industry: "Financial Services"

  # TODO: Uncomment when testimonials are approved for publication
  # testimonials:
  #   - quote: "Integrity Studio reduced our LLM debugging time by 73%. We now catch issues before our users do."
  #     author: "Joey Rahman"
  #     role: "VP of Engineering"
  #     company: "Granica.ai"
  #     metric: "73% faster"
  #     metric_context: "issue resolution"
  #
  #   - quote: "The EU AI Act compliance tools saved us months of preparation. Audit-ready documentation out of the box."
  #     author: "Matthew Gregory"
  #     role: "Development VP"
  #     company: "Hines Financial Group"
  #     metric: "3 months"
  #     metric_context: "compliance prep saved"
  #
  #   - quote: "We cut our LLM and operational overhead costs by 40% within the first month. The cost tracking alone pays for itself."
  #     author: "Alvin Cheung"
  #     role: "CEO"
  #     company: "DotFun"
  #     metric: "40%"
  #     metric_context: "cost reduction"
  #
  #   - quote: "Integrity Studio gave us the visibility and guidance we needed to meet regulatory requirements with confidence and ease. The compliance reports alone saved us weeks."
  #     author: "Monica Herrera Hernandez"
  #     role: "CEO"
  #     company: "Leora Home Health Care"
  #     metric: "weeks"
  #     metric_context: "compliance time saved"

# =============================================================================
# STATUS SECTION
# =============================================================================
status:
  title: "Platform Status"
  subtitle: "Real-time operational health and performance metrics"
  status_badge: "All Systems Operational"
  all_operational: true
  status_page_url: "https://integritystudio.ai/status"
  status_page_cta: "View Full Status Page"

  metrics:
    - label: "Uptime"
      value: *uptime
      sublabel: *uptime_sla
    - label: "Traces Processed"
      value: *traces_processed
      sublabel: *traces_period
    - label: "Setup Time"
      value: *setup_time
      sublabel: *setup_label

  services:
    - name: "Trace Ingestion API"
      status: "Operational"
    - name: "Dashboard & Analytics"
      status: "Operational"
    - name: "Compliance Reporting"
      status: "Operational"
    - name: "Alerting System"
      status: "Operational"

# =============================================================================
# ABOUT SECTION
# =============================================================================
about:
  section_id: "about"
  title: "About Integrity Studio"
  subtitle: "Building Trust in AI Systems"

  mission_statement: >-
    Empower enterprises to build trustworthy AI systems through comprehensive
    observability and governance tools.

  vision_statement: >-
    To be the standard for enterprise AI observability, enabling organizations
    to deploy AI confidently while meeting regulatory requirements.

  story: >-
    Integrity Studio was founded with a clear purpose: to solve the visibility problem
    in production AI systems. As LLMs and AI agents became critical to business operations,
    we saw teams struggling with black-box AI decisions, unpredictable costs, and looming
    regulatory requirements like the EU AI Act.


    Our founders built observability tools at scale before, and recognized that AI systems
    needed purpose-built monitoringâ€”not retrofitted APM solutions. We designed Integrity Studio
    from the ground up for the unique challenges of LLM applications: token-level cost attribution,
    multi-step agent tracing, and compliance documentation that satisfies auditors.


    Today, we help AI teams ship reliable, compliant applications faster. Our platform provides
    the visibility they need to debug issues, optimize costs, and demonstrate governance to
    stakeholdersâ€”all from a single pane of glass.

  values:
    - icon: "eye"
      title: "Transparency"
      description: >-
        We believe AI systems should be observable and explainable. Every decision,
        every cost, every outcome should be visible to the teams responsible for them.

    - icon: "shield-check"
      title: "Trust"
      description: >-
        Trust is earned through reliability, security, and accountability. We build tools
        that help our customers demonstrate trustworthiness to their users and regulators.

    - icon: "users"
      title: "Developer-First"
      description: >-
        Great tools should get out of the developer's way. We prioritize clean APIs,
        fast integration, and minimal overhead so teams can focus on building.

    - icon: "scale"
      title: "Compliance by Design"
      description: >-
        Regulatory requirements shouldn't be an afterthought. We embed compliance
        capabilities into the platform so governance happens automatically.

  team:
    - name: "Chase Hoffman"
      role: "Co-Founder and President"
      bio: >-
        Seasoned technology executive with deep expertise in scaling enterprise software companies.
        Focused on developing high-performance monetization systems and cost optimization that deliver exceptional customer success.

    - name: "Alyshia Ledlie"
      role: "Founder and CEO"
      bio: >-
        Deep experience building observability-first infrastructure at scale. Passionate about making
        AI systems transparent and trustworthy for enterprises navigating regulatory change.
      linkedin_url: "https://www.linkedin.com/in/aledlie"
      twitter_url: "https://twitter.com/alyshialedlie"

    - name: "Chandra Srivastava"
      role: "Co-founder & Chief Marketing Officer"
      bio: >-
        Marketing leader with experience driving growth at early stage B2B technology companies.
        Expert in positioning AI products for enterprise adoption and building category-defining brands.

    - name: "Micah Lindsay"
      role: "Chief Data Scientist"
      bio: >-
        Machine learning researcher focused on AI evaluation and observability.
        Developed novel approaches to precise hallucination detection and model performance analysis.

    - name: "John Skelton"
      role: "Head of Policy"
      bio: >-
        Regulatory and compliance expert specializing in AI governance frameworks.
        Advises enterprises on EU AI Act preparation and responsible AI deployment.

    - name: "Isabel Budenz"
      role: "AI Compliance Counsel"
      bio: >-
        International legal expert specializing in AI governance and EU AI Act compliance.
        Background in International Commercial Arbitration with multilingual research capabilities spanning German, Spanish, English, and French legal systems.


# =============================================================================
# CONTACT SECTION
# =============================================================================
contact:
  section_id: "contact"
  title: "Get in Touch"
  subtitle: "Let's discuss how we can help"
  description: >-
    Whether you're evaluating AI observability solutions, have questions about
    EU AI Act compliance, or want to see a demo, our team is here to help.
    Reach out and we'll respond within one business day.

  form:
    submit_text: "Send Message"
    success_message: "Thank you for reaching out! We'll get back to you within one business day."
    error_message: "Something went wrong. Please try again or email us directly at hello@integritystudio.ai"
    calendly_url: "https://calendly.com/alyshialedlie/30min"
    calendly_cta_text: "Schedule Demo"

    fields:
      - name: "firstName"
        label: "First Name"
        placeholder: "John"
        type: "text"
        required: true

      - name: "lastName"
        label: "Last Name"
        placeholder: "Smith"
        type: "text"
        required: true

      - name: "email"
        label: "Work Email"
        placeholder: "john@company.com"
        type: "email"
        required: true

      - name: "company"
        label: "Company"
        placeholder: "Acme Inc."
        type: "text"
        required: true

      - name: "companySize"
        label: "Company Size"
        placeholder: "Select..."
        type: "select"
        required: true
        options:
          - "1-10 employees"
          - "11-50 employees"
          - "51-200 employees"
          - "201-1,000 employees"
          - "1,000+ employees"

      - name: "useCase"
        label: "Primary Interest"
        placeholder: "Select..."
        type: "select"
        required: true
        options:
          - "LLM Monitoring & Cost Tracking"
          - "Agent Observability"
          - "EU AI Act Compliance"
          - "General AI Observability"
          - "Enterprise Evaluation"
          - "Partnership Inquiry"
          - "AI Implementation Consulting"

      - name: "message"
        label: "Message"
        placeholder: "Tell us about your AI observability needs..."
        type: "textarea"
        required: false

  contact_methods:
    - icon: "mail"
      label: "Email"
      value: "hello@integritystudio.ai"
      url: "mailto:hello@integritystudio.ai"
      is_primary: true

    - icon: "calendar"
      label: "Schedule a Demo"
      value: "Book a 30-minute call"
      url: "https://calendly.com/alyshialedlie/30min"
      is_primary: true

    - icon: "map-pin"
      label: "Location"
      value: "248 Addie Roy Road, Austin, TX 78746"
      url: "https://www.google.com/maps/place/248+Addie+Roy+Rd,+Austin,+TX+78746"

    - icon: "linkedin"
      label: "LinkedIn"
      value: "Follow us"
      url: "https://linkedin.com/company/integrity-studio-ai"

    - icon: "twitter"
      label: "Twitter"
      value: "@integritystudio"
      url: "https://twitter.com/integritystudio"

    - icon: "github"
      label: "GitHub"
      value: "integritystudio"
      url: "https://github.com/aledlie"

# =============================================================================
# FOOTER SECTION
# =============================================================================
footer:
  privacy_link: "/privacy"
  terms_link: "/terms"
  cookies_link: "/cookies"
  accessibility_link: "/accessibility"
  cookie_settings_label: "Cookie Settings"

  link_groups:
    - title: "Product"
      links:
        - label: "Features"
          url: "#features"
        - label: "Pricing"
          url: "#pricing"
        - label: "Documentation"
          url: "/docs"

    - title: "Company"
      links:
        - label: "About"
          url: "/about"
        - label: "Blog"
          url: "/blog"
        - label: "Careers"
          url: "/careers"
        - label: "Contact"
          url: "/contact"

    - title: "Resources"
      links:
        - label: "EU AI Act Guide"
          url: "/eu-ai-act"
        - label: "API Reference"
          url: "/api"
        - label: "Status"
          url: "https://integritystudio.ai/status"
          is_external: true
        - label: "Support"
          url: "/support"

# =============================================================================
# RESOURCES SECTION
# =============================================================================
resources:
  section_id: "resources"
  title: "Resources"
  subtitle: "Guides, Documentation & Insights"
  blog_cta_text: "View All Articles"
  blog_cta_url: "/blog"
  docs_cta_text: "Browse Documentation"
  docs_cta_url: "/docs"

  documentation:
    - icon: "book-open"
      title: "Getting Started"
      description: "Quick start guides and tutorials to get your first traces flowing in under 5 minutes."
      url: "/docs/quickstart"
      popular_topics:
        - "Python SDK Setup"
        - "TypeScript Integration"
        - "OpenTelemetry Configuration"
        - "Dashboard Overview"

    - icon: "code-2"
      title: "API Reference"
      description: "Complete API documentation with examples for all endpoints and SDK methods."
      url: "/docs/api"
      popular_topics:
        - "Trace Ingestion API"
        - "Query API"
        - "Alerts API"
        - "Authentication"

    - icon: "shield"
      title: "Compliance Guides"
      description: "In-depth guides for EU AI Act preparation, audit trails, and governance configuration."
      url: "/docs/compliance"
      popular_topics:
        - "EU AI Act Overview"
        - "Risk Classification"
        - "Audit Trail Setup"
        - "Human Oversight Workflows"

    - icon: "puzzle"
      title: "Integrations"
      description: "Connect Integrity Studio with your existing tools: Slack, PagerDuty, Datadog, and more."
      url: "/docs/integrations"
      popular_topics:
        - "Slack Notifications"
        - "PagerDuty Alerting"
        - "Grafana Dashboards"
        - "Webhook Configuration"

  featured_posts:
    - title: "Best LLM Monitoring Tools (2025 Guide)"
      excerpt: >-
        I tested 11 platforms so you can skip the free trial hamster wheel.
        Includes pricing, features, and honest recommendationsâ€”from Phoenix (free)
        to Arize ($50k+/year). Plus EU AI Act compliance considerations.
      category: "Comparison"
      publish_date: "2024-12-24"
      read_time: "18 min read"
      slug: "best-llm-monitoring-tools-2025"
      author: "Alyshia Ledlie"

    - title: "End-to-End Agentic Observability: From Chaos to Control"
      excerpt: >-
        Your AI agent just autonomously decided to email your entire customer database
        at 3 AM. Learn the Build, Test, Monitor, Analyze lifecycle that keeps agents
        reliable, compliant, and not accidentally ordering 10,000 pizzas.
      category: "Best Practices"
      publish_date: "2024-12-24"
      read_time: "12 min read"
      slug: "end-to-end-agentic-observability-lifecycle"
      author: "Alyshia Ledlie"

    # TODO: Create HTML file web/blog/eu-ai-act-engineering-guide.html
    # - title: "EU AI Act: What Engineering Teams Need to Know"
    #   excerpt: >-
    #     A practical guide to EU AI Act compliance for AI engineering teams.
    #     Understand Article 12 traceability requirements, risk classifications,
    #     and how to prepare your systems before enforcement begins.
    #   category: "Compliance"
    #   publish_date: "2024-12-15"
    #   read_time: "12 min read"
    #   slug: "eu-ai-act-engineering-guide"
    #   author: "Alyshia Ledlie"

    - title: "LLM Cost Calculator & Optimization Guide (2025)"
      excerpt: >-
        Compare API pricing for GPT-4, Claude, Gemini, and DeepSeek. Free calculator shows
        monthly costs. Learn techniques to reduce AI spending by 40-80%, from prompt caching
        to model routing.
      category: "Cost Optimization"
      publish_date: "2025-12-27"
      read_time: "5 min read"
      slug: "llm-cost-optimization-guide"
      author: "Alyshia Ledlie"

    # TODO: Create HTML file web/blog/ai-agent-observability-guide.html
    # - title: "Complete Guide to AI Agent Observability"
    #   excerpt: >-
    #     As autonomous AI agents become more complex, observability becomes critical.
    #     Learn how to trace multi-step workflows, debug tool calls, and monitor agent performance.
    #   category: "Best Practices"
    #   publish_date: "2024-12-05"
    #   read_time: "15 min read"
    #   slug: "ai-agent-observability-guide"
    #   author: "Alyshia Ledlie"

  lead_magnets:
    - icon: "clipboard-check"
      title: "EU AI Act Compliance Checklist"
      description: >-
        A comprehensive checklist covering all EU AI Act requirements for high-risk AI systems.
        Includes Article 12 traceability, documentation templates, and timeline milestones.
      format: "PDF"
      cta_text: "Download Checklist"
      url: "/resources/eu-ai-act-compliance-checklist"

    - icon: "calculator"
      title: "LLM Cost Calculator"
      description: >-
        Compare pricing across GPT-4, Claude, Gemini, and DeepSeek.
        Calculate monthly costs and discover optimization techniques to save 40-80%.
      format: "Interactive Tool"
      cta_text: "Calculate Savings"
      url: "/blog/llm-cost-optimization-guide#calculator"
      requires_email: false

    - icon: "file-text"
      title: "State of AI Observability 2025"
      description: >-
        Original research on AI observability trends, challenges, and best practices.
        Insights on monitoring, compliance, and cost management.
      format: "Report"
      cta_text: "Get the Report"
      url: "/reports/state-of-ai-observability-2025"

# =============================================================================
# LLM OBSERVABILITY DOCUMENTATION
# =============================================================================
llm_observability:
  meta:
    title: "LLM Observability Guide | Integrity Studio"
    description: "Integrity Studio's complete guide to context management, token optimization, and observability."
    canonical_url: "https://www.integritystudio.ai/docs/llm-observability"

  hero:
    badge: "Production-Ready Framework"
    title: "Claude Code Observability & Context Management"
    subtitle: "Integrity Studio's complete guide to token optimization, distributed tracing, and cost efficiency."
    stats:
      - value: "81%"
        label: "Cost Reduction"
      - value: "12"
        label: "Instrumented Hooks"
      - value: "8"
        label: "Dashboards"
      - value: "85%"
        label: "MCP Token Savings"

  sidebar:
    sections:
      - title: "Getting Started"
        items:
          - label: "Overview"
            anchor: "overview"
          - label: "Quick Start"
            anchor: "quick-start"
          - label: "Architecture"
            anchor: "architecture"
      - title: "Context Management"
        items:
          - label: "Token Optimization"
            anchor: "token-optimization"
          - label: "Efficient Tool Usage"
            anchor: "tool-usage"
          - label: "Context Window"
            anchor: "context-window"
          - label: "MCP Optimization"
            anchor: "mcp-optimization"
      - title: "Observability"
        items:
          - label: "OpenTelemetry Setup"
            anchor: "otel-setup"
          - label: "Instrumented Hooks"
            anchor: "instrumented-hooks"
          - label: "Metrics Reference"
            anchor: "metrics-reference"
          - label: "SigNoz Dashboards"
            anchor: "dashboards"
      - title: "Cost Analysis"
        items:
          - label: "Cost Optimization"
            anchor: "cost-optimization"
          - label: "Usage Patterns"
            anchor: "usage-patterns"
          - label: "Recommendations"
            anchor: "recommendations"

  sections:
    overview:
      title: "Overview"
      intro: >-
        Context management is "effectively the #1 job" for engineers building AI agents.
        As Anthropic emphasizes: "Claude is already smart enoughâ€”intelligence is not the bottleneck, context is."
      description: "This framework provides full visibility into Claude Code operations through:"
      features:
        - icon: "activity"
          title: "Distributed Tracing"
          description: "Track operations across hook invocations with OpenTelemetry spans and trace correlation."
        - icon: "bar-chart-3"
          title: "Metrics Collection"
          description: "Monitor performance, token usage, and cost patterns with real-time dashboards."
        - icon: "file-text"
          title: "Structured Logging"
          description: "Debug issues with logs correlated to trace context for full observability."
        - icon: "bot"
          title: "LLM Instrumentation"
          description: "Track token usage, costs, and model performance with Langtrace auto-instrumentation."
      key_results:
        title: "Key Results from Optimization"
        items:
          - metric: "81%"
            description: "reduction in cost per session"
          - metric: "84%"
            description: "reduction in tokens per session"
          - metric: "85%"
            description: "reduction in MCP tool overhead"
          - metric: "3x"
            description: "more work completed with same daily spend"

    quick_start:
      title: "Quick Start"
      # TODO: Add "claude mcp add observability-toolkit -- npx -y observability-toolkit" once API key access is configured
      coming_soon:
        title: "Coming Soon"
        items:
          - "One-command setup via MCP toolkit"
          - "Automatic configuration with API key"

    architecture:
      title: "Architecture"
      diagram: |
        Claude Code Hooks
                |
                v
          HookMonitor (otel-monitor.ts)
          - Initializes OTel SDK
          - Creates root span
          - Records metrics/logs
                |
                v
        +-------------------------------------------+
        |         Dual Export Pattern               |
        +-------------------------------------------+
        |  Local File Export    |   Remote OTLP     |
        |  (FileSpanExporter)   |   (SigNoz Cloud)  |
        |  JSONL Format         |   TLS + Auth      |
        |  ~/.claude/telemetry/ |   ingestion key   |
        +-------------------------------------------+
                |                       |
                v                       v
           Local Cache           SigNoz Dashboard
           (JSONL files)         (traces, metrics, logs)
      output_locations:
        title: "Output Locations"
        headers: ["Signal", "Local File", "Remote Endpoint"]
        rows:
          - ["Traces", "telemetry/traces-YYYY-MM-DD.jsonl", "/v1/traces"]
          - ["Metrics", "N/A (remote only)", "/v1/metrics"]
          - ["Logs", "telemetry/logs-YYYY-MM-DD.jsonl", "/v1/logs"]
          - ["LLM Events", "telemetry/llm-events-YYYY-MM-DD.jsonl", "Langtrace spans"]

    token_optimization:
      title: "Token Optimization Strategies"
      token_efficient_tools:
        title: "Token-Efficient Tool Use"
        description: "Claude 4 models have built-in token-efficient tool use that saves an average of 14% in output tokens (up to 70%) while reducing latency."
        code: "anthropic-beta: token-efficient-tools-2025-02-19"
        note: "For Claude Sonnet 3.7, enable with header"
      lazy_loading:
        title: "Dynamic/Lazy Context Loading"
        description: "Instead of loading verbose documentation upfront, use triggers to load detailed context on-demand."
        results:
          title: "Results from Lazy Loading"
          items:
            - "Initial context reduced from 7,584 to 3,434 tokens (54% reduction)"
            - "Monthly cost for 5 developers doing 100 sessions/day: $72 (62% savings)"
      hybrid_model:
        title: "Hybrid Model Approach"
        headers: ["Model", "Use For"]
        rows:
          - ["Opus 4.5", "High-level planning, architectural design, final code review"]
          - ["Sonnet/Haiku", "Implementation work, syntax validation, data parsing, quick checks"]

    tool_usage:
      title: "Efficient Tool Usage"
      tool_recommendations:
        title: "When to Use Each Tool"
        headers: ["Scenario", "Recommended Tool"]
        rows:
          - ["Find files by name pattern", "Glob"]
          - ["Search file contents", "Grep"]
          - ["Read known file", "Read (with offset/limit for large files)"]
          - ["Execute commands", "Bash (with output truncation)"]
          - ["Open-ended exploration", "Task/Subagent"]
          - ["Verbose operations", "Delegate to subagent"]
      bash_limiting:
        title: "Bash Output Limiting"
        code: |
          # Truncate test output
          npm test 2>&1 | tail -30

          # Filter for errors/warnings only
          npm run build 2>&1 | grep -i "error\|warning" || echo "Build succeeded"

          # Limit output to N lines
          command | head -100
      memory_warning:
        type: "warning"
        message: "Claude Code stores all bash output in memory for the entire session. Large outputs (90GB+ reported) can crash the application. Always truncate verbose commands."
      subagent_delegation:
        title: "Subagent Delegation"
        description: "Use subagents when:"
        items:
          - "The task produces verbose output you don't need in your main context"
          - "You want to enforce specific tool restrictions"
          - "The work is self-contained and can return a summary"
          - "Running tests, fetching documentation, or processing log files"

    context_window:
      title: "Context Window Management"
      limits:
        title: "Understanding Context Limits"
        headers: ["Tier", "Context Window", "Notes"]
        rows:
          - ["Standard", "200,000 tokens", "Default for most users"]
          - ["Advanced (Tier 4+)", "1,000,000 tokens", "Premium pricing applies"]
          - ["Premium threshold", ">200K tokens", "2x input, 1.5x output pricing"]
      critical_insight:
        type: "danger"
        message: "Avoid using the final 20% of your context window for complex tasks. Quality notably declines for memory-intensive operations."
      commands:
        title: "Built-in Commands"
        headers: ["Command", "Purpose", "When to Use"]
        rows:
          - ["/context", "Visualizes context usage", "Before deciding to compact"]
          - ["/clear", "Wipes conversation history", "Between tasks; when <50% context is relevant"]
          - ["/compact", "Summarizes conversation", "At 70% capacity; at logical breakpoints"]
          - ["/cost", "Shows token usage stats", "To understand patterns"]
      visualization: |
        Context: 45K tokens (22.5%)
           [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] ðŸŸ¢  (green < 50%)
           [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] ðŸŸ¡  (yellow 50-70%)
           [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] ðŸ”´  (red > 70%)

    mcp_optimization:
      title: "MCP Server Optimization"
      problem:
        title: "The Problem"
        description: "MCP tool definitions can consume massive context:"
        items:
          - "5-server setup: ~55K tokens before conversation starts"
          - "Jira alone: ~17K tokens"
          - "One reported case: 134K tokens of tool definitions"
      solution:
        title: "MCP Tool Search"
        description: "Reduces token overhead by 85% by loading tools on-demand rather than upfront."
        code: |
          # Auto mode (default) - activates when tools exceed threshold
          ENABLE_TOOL_SEARCH=auto

          # Custom threshold (5%)
          ENABLE_TOOL_SEARCH=auto:5

          # Disable entirely
          ENABLE_TOOL_SEARCH=false
      performance:
        title: "Performance Improvements"
        items:
          - "Opus 4: 49% to 74% accuracy"
          - "Opus 4.5: 79.5% to 88.1% accuracy"
          - "46.9% reduction in total agent tokens (51K to 8.5K)"
      manual_optimization:
        title: "Manual Optimization"
        steps:
          - "Use /context to identify consumption"
          - "Disable unused servers with @server-name disable or /mcp"
          - "Re-enable only when needed"

    otel_setup:
      title: "OpenTelemetry Setup"
      components:
        title: "Core Components"
        headers: ["Component", "File", "Purpose"]
        rows:
          - ["OTel Core", "hooks/lib/otel.ts", "SDK initialization, tracing, metrics, logging"]
          - ["Hook Monitor", "hooks/lib/otel-monitor.ts", "Simplified hook instrumentation"]
          - ["Langtrace", "hooks/lib/langtrace.ts", "Auto-instrument LLM API calls"]
          - ["Token Metrics", "hooks/lib/token-metrics.ts", "Cost and token tracking"]
      functions:
        title: "Key Functions"
        headers: ["Function", "Purpose"]
        rows:
          - ["initTelemetry()", "Initialize SDK with exporters"]
          - ["withSpan(name, attrs, fn)", "Wrap async function in a span"]
          - ["recordMetric(name, value, attrs)", "Record counter metric"]
          - ["recordGauge(name, value, attrs)", "Record gauge metric"]
          - ["logger.info/warn/error()", "Structured logging"]
          - ["getTraceUrl()", "Get SigNoz trace link"]
          - ["shutdown()", "Graceful cleanup"]
      pii_redaction:
        title: "Langtrace PII Redaction"
        description: "Auto-redacted patterns for sensitive data protection:"
        headers: ["Pattern", "Replacement"]
        rows:
          - ["Email addresses", "[EMAIL]"]
          - ["Phone numbers", "[PHONE]"]
          - ["SSN", "[SSN]"]
          - ["Credit card numbers", "[CREDIT_CARD]"]
          - ["API keys", "[API_KEY]"]
          - ["AWS access keys", "[AWS_KEY]"]
          - ["JWT tokens", "[JWT_TOKEN]"]

    instrumented_hooks:
      title: "Instrumented Hooks"
      headers: ["Hook", "Event", "Description"]
      rows:
        - ["session-start-otel.ts", "SessionStart", "Session initialization"]
        - ["mcp-pre-tool-otel.ts", "PreToolUse", "MCP tool invocation start"]
        - ["mcp-post-tool-otel.ts", "PostToolUse", "MCP tool completion"]
        - ["agent-pre-tool-otel.ts", "PreToolUse", "Subagent spawn"]
        - ["agent-post-tool-otel.ts", "PostToolUse", "Subagent completion"]
        - ["skill-activation-prompt-otel.ts", "UserPromptSubmit", "Skill detection"]
        - ["tsc-check-otel.ts", "PostToolUse", "TypeScript checks"]
        - ["stop-build-check-otel.ts", "Stop", "Build verification"]

    metrics_reference:
      title: "Metrics Reference"
      hook_metrics:
        title: "Hook Metrics"
        headers: ["Metric", "Type", "Description"]
        rows:
          - ["hook.duration", "Histogram", "Execution time distribution"]
          - ["hook.executions", "Counter", "Total invocations"]
          - ["mcp.invocations", "Counter", "MCP tool calls"]
          - ["agent.invocations", "Counter", "Subagent spawns"]
      genai_metrics:
        title: "GenAI Metrics"
        headers: ["Metric", "Type", "Description"]
        rows:
          - ["gen_ai.client.token.usage", "Counter", "Tokens consumed"]
          - ["gen_ai.client.cost", "Counter", "Cost in USD"]
          - ["gen_ai.client.operation.duration", "Histogram", "LLM call latency"]
      context_metrics:
        title: "Context Metrics"
        headers: ["Metric", "Description"]
        rows:
          - ["session.context.size", "Tokens at session start"]
          - ["session.context.utilization", "% of 200K window used"]
          - ["session.starts", "Session start counter"]

    dashboards:
      title: "SigNoz Dashboards"
      headers: ["Dashboard", "Purpose"]
      rows:
        - ["Claude Code Hooks Observability", "Core hook performance"]
        - ["Claude Code Hooks Performance", "Duration and status distribution"]
        - ["Token Usage & Cost Efficiency", "LLM consumption and costs"]
        - ["Tool & MCP Usage Analytics", "MCP server/tool usage"]
        - ["Error & Anomaly Detection", "Error monitoring"]
        - ["Build & Type Check Performance", "TSC/Python metrics"]
        - ["Subagent Analytics", "Agent invocations"]
        - ["Session Health Overview", "Session activity"]

    cost_optimization:
      title: "Cost Optimization"
      session_comparison:
        title: "Session Strategy Comparison"
        headers: ["Metric", "Before", "After", "Change"]
        rows:
          - ["Avg Sessions/Day", "7.3", "26.2", "+259%"]
          - ["Tokens/Session", "40,246", "6,503", "-84%"]
          - ["Cost/Session", "$22.17", "$3.64", "-84%"]
          - ["Cost/Message", "$0.067", "$0.021", "-69%"]
      pattern:
        title: "The Pattern"
        items:
          - "Before: Fewer, longer sessions (avg 40K tokens each) â†’ Context grows large â†’ expensive"
          - "After: More, shorter sessions (avg 6.5K tokens each) â†’ Context stays small â†’ efficient"
      cost_by_category:
        title: "Cost by Category"
        headers: ["Category", "Cost", "% of Total"]
        rows:
          - ["Cache Read", "$1,916.70", "52.2%"]
          - ["Cache Write", "$1,649.57", "44.9%"]
          - ["Output", "$94.16", "2.6%"]
          - ["Input", "$13.94", "0.4%"]
        insight: "Cache operations = 97% of cost. Without caching, input would cost ~$19,600 (5.3x more expensive)."

    usage_patterns:
      title: "Usage Patterns"
      research_vs_implementation:
        title: "Research vs Implementation"
        headers: ["Activity", "Tokens/Message", "Cost Efficiency"]
        rows:
          - ["Research", "100-150", "Low"]
          - ["Implementation", "4-5", "High"]
      spike_analysis:
        title: "Spike Day Analysis"
        headers: ["Day", "Type", "Sessions", "Tokens", "Tokens/Session"]
        rows:
          - ["Dec 14", "Research", "27", "1.08M", "39,922"]
          - ["Jan 11", "Research", "22", "1.38M", "62,533"]
          - ["Jan 17", "Implementation", "16", "104K", "6,517"]
          - ["Jan 19", "Rapid iteration", "83", "499K", "6,008"]

    recommendations:
      title: "Recommendations"
      maintain_gains:
        title: "Maintain the Gains"
        items:
          - "Keep sessions short â€” Target <10K tokens/session"
          - "Reset frequently â€” New session after major task completion"
          - "Compact at 70% â€” Don't let context hit limits"
          - "Monitor trends â€” Watch session.context.utilization in SigNoz"
      optimize_further:
        title: "Optimize Further"
        items:
          - "Batch research â€” Dedicate specific sessions to exploration"
          - "Use subagents â€” Delegate verbose operations"
          - "Truncate output â€” | tail -30 for logs, use offset/limit for files"
      daily_workflow:
        title: "Daily Workflow"
        code: |
          1. Start session
             - /context to check baseline
             - Disable unused MCP servers

          2. During work
             - Use subagents for verbose operations
             - Truncate bash output
             - Read files with offset/limit for large files
             - Use Grep output_mode: "files_with_matches"

          3. Between tasks
             - /clear if <50% context is relevant
             - /compact at 70% capacity

          4. End of session
             - Document progress in .md file
             - /cost to review usage
      config_cleanup:
        title: "Config Cleanup Impact"
        headers: ["File", "Before", "After", "Reduction"]
        rows:
          - ["settings.local.json", "1.8 KB", "303 bytes", "83%"]
          - ["settings.json", "2.8 KB", "2.2 KB", "21%"]
          - ["skill-rules.json", "14.4 KB", "13.8 KB", "4%"]
          - ["marketplaces.json", "3.6 KB", "2.8 KB", "23%"]

  footer:
    built_with:
      - name: "OpenTelemetry"
        url: "https://opentelemetry.io"
      - name: "SigNoz"
        url: "https://signoz.io"
    copyright: "Â© 2026 Integrity Studio. All rights reserved."

# =============================================================================
# BLOG CONTENT
# =============================================================================
blog:
  _meta:
    last_reviewed: "2026-01-30"
    review_owner: "marketing"
  page_title: "Insights & Research"
  page_subtitle: >-
    Deep dives into AI observability, market trends, regulatory compliance,
    and strategic insights for building trustworthy AI systems.

  posts:
    # ------------------------------------------
    # Comparison/Migration Articles (internal)
    # ------------------------------------------
    - title: "WhyLabs Alternative: Migrate to Integrity Studio"
      subtitle: "WhyLabs Is Shutting Downâ€”Here's Your Migration Path"
      description: >-
        WhyLabs announced shutdown on March 9, 2025. This guide covers migrating
        your AI observability to Integrity Studio with privacy-first monitoring,
        EU AI Act compliance, and seamless data migrationâ€”most teams complete it
        in under an hour.
      date: "September 15, 2025"
      read_time: "8 min read"
      category: "Migration"
      url: "/whylabs-alternative"
      is_internal: true
      stats:
        - "Under 1 hour migration"
        - "EU AI Act ready"
        - "Privacy-first"

    - title: "Arize AI vs Integrity Studio: Comparison Guide"
      subtitle: "A Simpler Path to AI Observability"
      description: >-
        Comparing Integrity Studio and Arize AI for AI observability. Learn about
        transparent pricing, EU AI Act compliance, and developer-friendly integration.
        Find the right platform for your LLM monitoring needs.
      date: "January 20, 2025"
      read_time: "6 min read"
      category: "Comparison"
      url: "/compare/arize-ai-alternative"
      is_internal: true
      stats:
        - "5-minute setup"
        - "Transparent pricing"
        - "Compliance built-in"

    # ------------------------------------------
    # External Blog Articles
    # ------------------------------------------
    - title: "Setting Up Compliance Logging for EU AI Act"
      subtitle: "Technical Guide to Article 12-Compliant Logging"
      description: >-
        A practical guide to implementing Article 12-compliant logging for LLM
        systems, with code examples and production-ready patterns. Covers ISO 24970
        standards, data schemas, and implementation for high-risk AI compliance.
      date: "December 26, 2024"
      read_time: "15 min read"
      category: "Compliance"
      url: "/blog/eu-ai-act-compliance-logging-setup.html"
      stats:
        - "August 2026 deadline"
        - "ISO 24970 aligned"
        - "Production code"

    - title: "Best LLM Monitoring Tools (2025 Guide)"
      subtitle: "We Tested 11 Platforms So You Don't Have To"
      description: >-
        The definitive guide to LLM monitoring and observability tools. Includes
        pricing, features, and honest recommendations for startups to enterprises.
        Covers Langfuse, LangSmith, Helicone, Arize, Datadog, and more.
      date: "December 15, 2025"
      read_time: "18 min read"
      category: "Comparison"
      url: "/blog/best-llm-monitoring-tools-2025.html"
      stats:
        - "11 tools compared"
        - "$1.97B market 2025"
        - "Startup to Enterprise"

    - title: "End-to-End Agentic Observability: From Chaos to Control"
      subtitle: "A Practical Guide to the 4-Stage Observability Lifecycle"
      description: >-
        Your AI agent just autonomously decided to email your entire customer
        database at 3 AM. With a coupon code that doesn't exist. In French.
        Learn the Build, Test, Monitor, Analyze lifecycle that keeps agents
        reliable and compliant.
      date: "December 24, 2024"
      read_time: "12 min read"
      category: "Best Practices"
      url: "/blog/end-to-end-agentic-observability-lifecycle.html"
      stats:
        - "73% faster debugging"
        - "4-stage lifecycle"
        - "EU AI Act ready"

    - title: "AI Observability Platform Strategy"
      subtitle: "Enhanced Research Report: Market Analysis, Regulatory Compliance & Competitive Intelligence"
      description: >-
        Comprehensive market research and strategic analysis for AI Observability
        and Trust Platform positioning, with regulatory compliance insights and
        competitive landscape analysis.
      date: "December 8, 2024"
      read_time: "45 min read"
      category: "Strategy"
      url: "/blog/ai-observability-platform-strategy/index.html"
      is_series: true
      series_articles:
        - title: "Market Analysis"
          description: "Market size validation, enterprise budget trends, and growth projections"
          url: "/blog/ai-observability-platform-strategy/market-analysis.html"
        - title: "Regulatory Drivers"
          description: "EU AI Act compliance timeline and requirements breakdown"
          url: "/blog/ai-observability-platform-strategy/regulatory-drivers.html"
        - title: "Competitive Landscape"
          description: "Competitor analysis with funding data and market segmentation"
          url: "/blog/ai-observability-platform-strategy/competitive-landscape.html"
        - title: "Growth Strategy"
          description: "Product-led growth validation and pricing benchmarks"
          url: "/blog/ai-observability-platform-strategy/growth-strategy.html"
        - title: "Recommendations"
          description: "Prioritized actions with validation metrics and risk analysis"
          url: "/blog/ai-observability-platform-strategy/recommendations.html"
        - title: "Sources"
          description: "Complete reference list with all research sources"
          url: "/blog/ai-observability-platform-strategy/sources.html"
      stats:
        - "$2.9B+ market size by 2030"
        - "25.47% CAGR growth rate"
        - "98% enterprises increasing budgets"
